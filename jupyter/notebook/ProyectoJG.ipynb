{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de ventas de tiendas Walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"pyspark-walmart\")\n",
    "    .config(\"spark.driver.memory\", \"512m\")\n",
    "    .config(\"spark.driver.cores\", \"1\")\n",
    "    .config(\"spark.executor.memory\", \"512m\")\n",
    "    .config(\"spark.executor.cores\", \"1\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = spark.read.csv('/dataset/Walmart.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.select("Date").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date,col",
    "dff = dff.withColumn("Date",to_date("Date","dd-MM-yyyy"))",
    "from pyspark.sql.types import IntegerType, DoubleType, FloatType,
    "dff = dff.withColumn('Store', dff['Store'].cast(IntegerType()))",
    "dff = dff.withColumn('Holiday_Flag', dff['Holiday_Flag'].cast(DoubleType()))",
    "dff = dff.withColumn('Temperature', dff['Temperature'].cast(DoubleType()))",
    "dff = dff.withColumn('Fuel_Price', dff['Fuel_Price'].cast(DoubleType()))",
    "dff = dff.withColumn('CPI', dff['CPI'].cast(DoubleType()))",
    "dff = dff.withColumn('Unemployment', dff['Unemployment'].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.summary().show()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupBy("Holiday_Flag").count().show()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupBy().sum("Weekly_Sales").show()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupBy('Store').sum('Weekly_Sales').orderBy('Store').show(20)"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupBy('Store').agg({"Weekly_Sales": "avg", "Weekly_Sales": "sum"}).sort('sum(Weekly_Sales)').show()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = dff.groupby('Store').sum('Weekly_Sales').orderBy('Store')",
    "stores.orderBy(stores['sum(Weekly_Sales)'].desc()).show(truncate=False)",
    "type(stores)" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.show()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stores_pd = stores.toPandas()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stores_pd"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Stores_pd)"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt",
    "%matplotlib inline",
    "Stores_pd.plot.bar(x='Store', y='sum(Weekly_Sales)', figsize=(20,6))"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupby('Date').sum('Weekly_Sales').orderBy('Date').show(10)"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semana = dff.groupBy('Date').sum('Weekly_Sales').orderBy('Date')"
   ]
  }, 
     {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semana_pd = semana.toPandas()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt",
    "%matplotlib inline",
    "semana_pd.plot.bar(x='Date', y='sum(Weekly_Sales)', figsize=(20,6))"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format",
    "dff = dff.withColumn("Year",date_format("Date","yyyy")).withColumn("Month",date_format("Date","MM"))",
    "dff.show(5)"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupBy('Year').sum('Weekly_Sales').orderBy('Year').show()"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F",
    "dff = dff.withColumn("yearday",F.dayofyear(F.col("Date"))).withColumn('WeekOfYear',F.weekofyear(F.col('Date')))",
    "dff.show(5)"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupBy('Year', 'Month' ).sum('Weekly_Sales').orderBy('Year', 'Month').show(5)"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_año = dff.groupBy('Year', 'Month').sum('Weekly_Sales').orderBy('Year', 'Month')"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_año_pd = ventas_año.toPandas()"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_año_pd"
   ]
  }, 
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_año_pd.plot.bar(x='Month', y='sum(Weekly_Sales)', color ='green', figsize=(20,6) )"
   ]
  }, 
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
